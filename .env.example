# GitHub API Configuration
GITHUB_TOKEN=your_github_token_here

OPENAI_API_KEY=your_openai_api_key_here

# Application Configuration
LOG_LEVEL=INFO
DEBUG=False

# Cache Configuration
CACHE_TTL_HOURS=24
MAX_CACHE_SIZE_MB=100

# Analysis Configuration
MIN_SCORE_THRESHOLD=70.0
MAX_FORKS_TO_ANALYZE=100
AUTO_PR_ENABLED=False

# Rate Limiting
REQUESTS_PER_MINUTE=60
MAX_CONCURRENT_REQUESTS=10
